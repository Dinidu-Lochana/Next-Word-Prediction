# -*- coding: utf-8 -*-
"""Next-Word-Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZqF8S-HnXgBFcWYorZGjgWWKV9lNfWEz
"""

import numpy as np
import tensorflow as tf

with open("/content/Evo_IX.txt", 'r', encoding='utf-8') as file:
    evo_ix = file.read()

evo_ix

tokenizer = tf.keras.preprocessing.text.Tokenizer()

tokenizer.fit_on_texts([evo_ix])

tokenizer.get_config()

tokenizer.word_index

for sentence in evo_ix.split('\n'):
    print(sentence)
    token_sentence = tokenizer.texts_to_sequences([sentence])[0]
    print(token_sentence)

input_sequences = []

for sentence in evo_ix.split('\n'):

    token_sentence = tokenizer.texts_to_sequences([sentence])[0]

    for i in range(1, len(token_sentence)):
        sequence = token_sentence[:i+1]
        input_sequences.append(sequence)

input_sequences[:5]

max_length = max([len(x) for x in input_sequences])
max_length

input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_length, padding='pre'))

input_sequences[:5]

X = input_sequences[:, :-1]
y = input_sequences[:, -1]

X[0]

y[0]

num_classes = len(tokenizer.word_index) + 1
num_classes

y = np.array(tf.keras.utils.to_categorical(y, num_classes=num_classes))

y[0]

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Embedding(num_classes, 80))
model.add(tf.keras.layers.LSTM(100))
model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

history = model.fit(X, y, epochs=100)

input_text = "Evolution IX was produced"

token_list = tokenizer.texts_to_sequences([input_text])[0]
token_list

token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_length-1, padding='pre')
token_list

predicted = np.argmax(model.predict(token_list), axis=-1)
predicted

for word, index in tokenizer.word_index.items():
    if index == predicted:
        print(word)

for i in range(6):
    token_list = tokenizer.texts_to_sequences([input_text])[0]
    token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_length-1, padding='pre')
    predicted = np.argmax(model.predict(token_list), axis=-1)
    output_word = ""
    for word, index in tokenizer.word_index.items():
        if index == predicted:
            output_word = word
            break
    input_text += " " + output_word

print(input_text)